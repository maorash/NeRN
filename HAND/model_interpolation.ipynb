{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pyrallis\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from clearml import Task\n",
    "\n",
    "from HAND.HAND_train import load_original_model\n",
    "from HAND.loss.attention_loss import AttentionLossFactory\n",
    "from HAND.loss.distillation_loss import DistillationLossFactory\n",
    "from HAND.loss.reconstruction_loss import ReconstructionLossFactory\n",
    "from HAND.loss.task_loss import TaskLossFactory\n",
    "from HAND.options import TrainConfig\n",
    "from HAND.predictors.factory import HANDPredictorFactory\n",
    "from HAND.tasks.model_factory import ModelFactory\n",
    "import HAND.log_utils as log_utils\n",
    "from HAND.trainer import Trainer\n",
    "from HAND.eval_func import EvalFunction\n",
    "from HAND.tasks.dataloader_factory import DataloaderFactory\n",
    "from HAND.tasks.model_factory import ModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_predictor(cfg, predictor):\n",
    "    if cfg.hand.init == \"fmod\":\n",
    "        print(\"Initializing using fmod\")\n",
    "        for p in predictor.parameters():\n",
    "            if len(p.shape) >= 2:\n",
    "                p.data = torch.fmod(p.data, 2)\n",
    "    elif cfg.hand.init == \"checkpoint\":\n",
    "        print(f\"Loading pretrained weights from: {cfg.hand.checkpoint_path}\")\n",
    "        predictor.load(cfg.hand.checkpoint_path)\n",
    "    elif cfg.hand.init == \"default\":\n",
    "        print(\"Using default torch initialization\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported initialization method: {cfg.hand.init}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = pyrallis.load(TrainConfig,\n",
    "                              open('experiments/resnet56/cifar10/debug_interpolation.yaml',\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not cfg.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load precomputed embeddings\n",
      "Couldn't load precomputed embeddings, computing embeddings\n",
      "Calculating layer 1/57 embeddings\n",
      "Calculating layer 2/57 embeddings\n",
      "Calculating layer 3/57 embeddings\n",
      "Calculating layer 4/57 embeddings\n",
      "Calculating layer 5/57 embeddings\n",
      "Calculating layer 6/57 embeddings\n",
      "Calculating layer 7/57 embeddings\n",
      "Calculating layer 8/57 embeddings\n",
      "Calculating layer 9/57 embeddings\n",
      "Calculating layer 10/57 embeddings\n",
      "Calculating layer 11/57 embeddings\n",
      "Calculating layer 12/57 embeddings\n",
      "Calculating layer 13/57 embeddings\n",
      "Calculating layer 14/57 embeddings\n",
      "Calculating layer 15/57 embeddings\n",
      "Calculating layer 16/57 embeddings\n",
      "Calculating layer 17/57 embeddings\n",
      "Calculating layer 18/57 embeddings\n",
      "Calculating layer 19/57 embeddings\n",
      "Calculating layer 20/57 embeddings\n",
      "Calculating layer 21/57 embeddings\n",
      "Calculating layer 22/57 embeddings\n",
      "Calculating layer 23/57 embeddings\n",
      "Calculating layer 24/57 embeddings\n",
      "Calculating layer 25/57 embeddings\n",
      "Calculating layer 26/57 embeddings\n",
      "Calculating layer 27/57 embeddings\n",
      "Calculating layer 28/57 embeddings\n",
      "Calculating layer 29/57 embeddings\n",
      "Calculating layer 30/57 embeddings\n",
      "Calculating layer 31/57 embeddings\n",
      "Calculating layer 32/57 embeddings\n",
      "Calculating layer 33/57 embeddings\n",
      "Calculating layer 34/57 embeddings\n",
      "Calculating layer 35/57 embeddings\n",
      "Calculating layer 36/57 embeddings\n",
      "Calculating layer 37/57 embeddings\n",
      "Calculating layer 38/57 embeddings\n",
      "Calculating layer 39/57 embeddings\n",
      "Calculating layer 40/57 embeddings\n",
      "Calculating layer 41/57 embeddings\n",
      "Calculating layer 42/57 embeddings\n",
      "Calculating layer 43/57 embeddings\n",
      "Calculating layer 44/57 embeddings\n",
      "Calculating layer 45/57 embeddings\n",
      "Calculating layer 46/57 embeddings\n",
      "Calculating layer 47/57 embeddings\n",
      "Calculating layer 48/57 embeddings\n",
      "Calculating layer 49/57 embeddings\n",
      "Calculating layer 50/57 embeddings\n",
      "Calculating layer 51/57 embeddings\n",
      "Calculating layer 52/57 embeddings\n",
      "Calculating layer 53/57 embeddings\n",
      "Calculating layer 54/57 embeddings\n",
      "Calculating layer 55/57 embeddings\n",
      "Calculating layer 56/57 embeddings\n",
      "Calculating layer 57/57 embeddings\n",
      "Saving positional embeddings for layer 1/57\n",
      "Saving positional embeddings for layer 2/57\n",
      "Saving positional embeddings for layer 3/57\n",
      "Saving positional embeddings for layer 4/57\n",
      "Saving positional embeddings for layer 5/57\n",
      "Saving positional embeddings for layer 6/57\n",
      "Saving positional embeddings for layer 7/57\n",
      "Saving positional embeddings for layer 8/57\n",
      "Saving positional embeddings for layer 9/57\n",
      "Saving positional embeddings for layer 10/57\n",
      "Saving positional embeddings for layer 11/57\n",
      "Saving positional embeddings for layer 12/57\n",
      "Saving positional embeddings for layer 13/57\n",
      "Saving positional embeddings for layer 14/57\n",
      "Saving positional embeddings for layer 15/57\n",
      "Saving positional embeddings for layer 16/57\n",
      "Saving positional embeddings for layer 17/57\n",
      "Saving positional embeddings for layer 18/57\n",
      "Saving positional embeddings for layer 19/57\n",
      "Saving positional embeddings for layer 20/57\n",
      "Saving positional embeddings for layer 21/57\n",
      "Saving positional embeddings for layer 22/57\n",
      "Saving positional embeddings for layer 23/57\n",
      "Saving positional embeddings for layer 24/57\n",
      "Saving positional embeddings for layer 25/57\n",
      "Saving positional embeddings for layer 26/57\n",
      "Saving positional embeddings for layer 27/57\n",
      "Saving positional embeddings for layer 28/57\n",
      "Saving positional embeddings for layer 29/57\n",
      "Saving positional embeddings for layer 30/57\n",
      "Saving positional embeddings for layer 31/57\n",
      "Saving positional embeddings for layer 32/57\n",
      "Saving positional embeddings for layer 33/57\n",
      "Saving positional embeddings for layer 34/57\n",
      "Saving positional embeddings for layer 35/57\n",
      "Saving positional embeddings for layer 36/57\n",
      "Saving positional embeddings for layer 37/57\n",
      "Saving positional embeddings for layer 38/57\n",
      "Saving positional embeddings for layer 39/57\n",
      "Saving positional embeddings for layer 40/57\n",
      "Saving positional embeddings for layer 41/57\n",
      "Saving positional embeddings for layer 42/57\n",
      "Saving positional embeddings for layer 43/57\n",
      "Saving positional embeddings for layer 44/57\n",
      "Saving positional embeddings for layer 45/57\n",
      "Saving positional embeddings for layer 46/57\n",
      "Saving positional embeddings for layer 47/57\n",
      "Saving positional embeddings for layer 48/57\n",
      "Saving positional embeddings for layer 49/57\n",
      "Saving positional embeddings for layer 50/57\n",
      "Saving positional embeddings for layer 51/57\n",
      "Saving positional embeddings for layer 52/57\n",
      "Saving positional embeddings for layer 53/57\n",
      "Saving positional embeddings for layer 54/57\n",
      "Saving positional embeddings for layer 55/57\n",
      "Saving positional embeddings for layer 56/57\n",
      "Saving positional embeddings for layer 57/57\n"
     ]
    }
   ],
   "source": [
    "original_model, reconstructed_model = load_original_model(cfg, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing using fmod\n",
      "Predictor:\t-> Number of parameters: 321.705K\t-> Size: 1.23Mb\n",
      "\n",
      "Original Model:\t-> Number of learnable parameters: 850.864K\t-> Size of learnable parameters: 3.25Mb \n",
      "\t-> Total model size: 3.26Mb\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported task",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/nfs/private/shir/HANDCompress/HAND/tasks/dataloader_factory.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(task_cfg, **kwargs)\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m             \u001B[0mtask_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataloaderFactory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtasks_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtask_cfg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtask_name\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m             \u001B[0mdataloaders\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtask_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"loader\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_kwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_kwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtask_cfg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtask_cfg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'cifar100'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_19913/2288518047.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m dataloaders = DataloaderFactory.get(cfg.task, **{'batch_size': cfg.batch_size,\n\u001B[0;32m---> 34\u001B[0;31m                                                  'num_workers': cfg.num_workers})\n\u001B[0m",
      "\u001B[0;32m/nfs/private/shir/HANDCompress/HAND/tasks/dataloader_factory.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(task_cfg, **kwargs)\u001B[0m\n\u001B[1;32m     58\u001B[0m                 \u001B[0mdataloaders\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnew_dataloaders\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Unsupported task\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdataloaders\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Unsupported task"
     ]
    }
   ],
   "source": [
    "pos_embedding = reconstructed_model.output_size\n",
    "from HAND.predictors.factory import HANDPredictorFactory, PredictorDataParallel\n",
    "\n",
    "predictor = HANDPredictorFactory(cfg, input_size=pos_embedding).get_predictor().to(device)\n",
    "predictor = PredictorDataParallel(predictor)\n",
    "predictor.load_state_dict(torch.load(\"/nfs/private/Maor/HANDCompress/HAND/outputs/resnet56_0_B_cifar10_ranger_nogc_350_epochs_1.1MB_base0.76_size40_1_31_08_2022_122955/hand_resnet56_0_B_cifar10_ranger_nogc_350_epochs_1.1MB_base0.76_size40_1_best.pth\").state_dict())\n",
    "\n",
    "init_predictor(cfg, predictor)\n",
    "\n",
    "if not cfg.logging.disable_logging:\n",
    "    if cfg.logging.use_tensorboard:\n",
    "        logger = SummaryWriter(log_dir=os.path.join(cfg.logging.log_dir, \"tb_logs\", cfg.logging.exp_name))\n",
    "        logger.add_text(\"TrainConfig\", json.dumps(pyrallis.encode(cfg), indent=4))\n",
    "    else:\n",
    "        clearml_task = Task.init(project_name='HAND_compression', task_name=cfg.logging.exp_name, deferred_init=True)\n",
    "        clearml_task.connect(log_utils.flatten(pyrallis.encode(cfg)))  # Flatten because of clearml bug\n",
    "        logger = clearml_task.get_logger()\n",
    "else:\n",
    "    logger = None\n",
    "\n",
    "num_predictor_params = sum([p.numel() for p in predictor.parameters()])\n",
    "print(f\"Predictor:\"\n",
    "      f\"\\t-> Number of parameters: {num_predictor_params / 1000}K\"\n",
    "      f\"\\t-> Size: {num_predictor_params * 4 / 1024 / 1024:.2f}Mb\")\n",
    "\n",
    "num_predicted_params = sum([p.numel() for p in original_model.get_learnable_weights()])\n",
    "num_total_params = sum([p.numel() for p in original_model.parameters()])\n",
    "print(f\"\\nOriginal Model:\"\n",
    "      f\"\\t-> Number of learnable parameters: {num_predicted_params / 1000}K\"\n",
    "      f\"\\t-> Size of learnable parameters: {num_predicted_params * 4 / 1024 / 1024:.2f}Mb\",\n",
    "      f\"\\n\\t-> Total model size: {num_total_params * 4 / 1024 / 1024:.2f}Mb\")\n",
    "\n",
    "dataloaders = DataloaderFactory.get(cfg.task, **{'batch_size': cfg.batch_size,\n",
    "                                                 'num_workers': cfg.num_workers})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HAND.predictors.predictor import HANDPredictorBase\n",
    "indices, positional_embeddings = reconstructed_model.get_indices_and_positional_embeddings()\n",
    "original_weights = original_model.get_learnable_weights()\n",
    "learnable_weights_shapes = reconstructed_model.get_learnable_weights_shapes()\n",
    "\n",
    "reconstructed_weights = HANDPredictorBase.predict_all(predictor, positional_embeddings,\n",
    "                                                          original_weights,\n",
    "                                                          learnable_weights_shapes)\n",
    "reconstructed_model.update_weights(reconstructed_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval on test set.\n",
      "\n",
      "Test set: Average loss: -17.2330, Accuracy: 9352/10000 (94%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.52"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from HAND.eval_func import EvalFunction\n",
    "eval_fn = EvalFunction(cfg)\n",
    "eval_fn.eval(original_model,dataloaders[1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval on test set.\n",
      "\n",
      "Test set: Average loss: -10.0224, Accuracy: 8751/10000 (88%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.51"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_fn.eval(reconstructed_model,dataloaders[1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load precomputed embeddings\n",
      "Loaded positional embeddings for layer 1/55\n",
      "Loaded positional embeddings for layer 2/55\n",
      "Loaded positional embeddings for layer 3/55\n",
      "Loaded positional embeddings for layer 4/55\n",
      "Loaded positional embeddings for layer 5/55\n",
      "Loaded positional embeddings for layer 6/55\n",
      "Loaded positional embeddings for layer 7/55\n",
      "Loaded positional embeddings for layer 8/55\n",
      "Loaded positional embeddings for layer 9/55\n",
      "Loaded positional embeddings for layer 10/55\n",
      "Loaded positional embeddings for layer 11/55\n",
      "Loaded positional embeddings for layer 12/55\n",
      "Loaded positional embeddings for layer 13/55\n",
      "Loaded positional embeddings for layer 14/55\n",
      "Loaded positional embeddings for layer 15/55\n",
      "Loaded positional embeddings for layer 16/55\n",
      "Loaded positional embeddings for layer 17/55\n",
      "Loaded positional embeddings for layer 18/55\n",
      "Loaded positional embeddings for layer 19/55\n",
      "Loaded positional embeddings for layer 20/55\n",
      "Loaded positional embeddings for layer 21/55\n",
      "Loaded positional embeddings for layer 22/55\n",
      "Loaded positional embeddings for layer 23/55\n",
      "Loaded positional embeddings for layer 24/55\n",
      "Loaded positional embeddings for layer 25/55\n",
      "Loaded positional embeddings for layer 26/55\n",
      "Loaded positional embeddings for layer 27/55\n",
      "Loaded positional embeddings for layer 28/55\n",
      "Loaded positional embeddings for layer 29/55\n",
      "Loaded positional embeddings for layer 30/55\n",
      "Loaded positional embeddings for layer 31/55\n",
      "Loaded positional embeddings for layer 32/55\n",
      "Loaded positional embeddings for layer 33/55\n",
      "Loaded positional embeddings for layer 34/55\n",
      "Loaded positional embeddings for layer 35/55\n",
      "Loaded positional embeddings for layer 36/55\n",
      "Loaded positional embeddings for layer 37/55\n",
      "Loaded positional embeddings for layer 38/55\n",
      "Loaded positional embeddings for layer 39/55\n",
      "Loaded positional embeddings for layer 40/55\n",
      "Loaded positional embeddings for layer 41/55\n",
      "Loaded positional embeddings for layer 42/55\n",
      "Loaded positional embeddings for layer 43/55\n",
      "Loaded positional embeddings for layer 44/55\n",
      "Loaded positional embeddings for layer 45/55\n",
      "Loaded positional embeddings for layer 46/55\n",
      "Loaded positional embeddings for layer 47/55\n",
      "Loaded positional embeddings for layer 48/55\n",
      "Loaded positional embeddings for layer 49/55\n",
      "Loaded positional embeddings for layer 50/55\n",
      "Loaded positional embeddings for layer 51/55\n",
      "Loaded positional embeddings for layer 52/55\n",
      "Loaded positional embeddings for layer 53/55\n",
      "Loaded positional embeddings for layer 54/55\n",
      "Loaded positional embeddings for layer 55/55\n",
      "Finished loading precomputed embeddings\n"
     ]
    }
   ],
   "source": [
    "from HAND.tasks.resnet56 import ResNet56X2, ReconstructedResNet56X2\n",
    "resnetx2_model = ResNet56X2().to(device)\n",
    "resnetx2_recon = ReconstructedResNet56X2(resnetx2_model, cfg, device, sampling_mode=cfg.hand.sampling_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 3, 3])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnetx2_model.get_learnable_weights()[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16, 3, 3])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model.get_learnable_weights()[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_x2, positional_embeddings_x2 = resnetx2_recon.get_indices_and_positional_embeddings()\n",
    "original_weights_x2 = resnetx2_model.get_learnable_weights()\n",
    "learnable_weights_shapes_x2 = resnetx2_recon.get_learnable_weights_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 240])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embeddings_x2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 240])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_embeddings[0][0]-positional_embeddings_x2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_weights_x2 = HANDPredictorBase.predict_all(predictor, positional_embeddings_x2,\n",
    "                                                          original_weights_x2,\n",
    "                                                          learnable_weights_shapes_x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetx2_recon.update_weights(reconstructed_weights_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval on test set.\n",
      "\n",
      "Test set: Average loss: nan, Accuracy: 1076/10000 (11%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.76"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_fn.eval(resnetx2_recon,dataloaders[1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet56X2' object has no attribute 'module'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_11736/886108931.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresnetx2_recon\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreconstructed_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"./reconstructed_x2_weights.pth\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/anaconda/envs/hand_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1176\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mmodules\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1177\u001B[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001B[0;32m-> 1178\u001B[0;31m             type(self).__name__, name))\n\u001B[0m\u001B[1;32m   1179\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1180\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__setattr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Module'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'ResNet56X2' object has no attribute 'module'"
     ]
    }
   ],
   "source": [
    "torch.save(resnetx2_recon.reconstructed_model.state_dict(), \"./reconstructed_x2_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting eval on test set.\n",
      "\n",
      "Test set: Average loss: 1.9539, Accuracy: 1000/10000 (10%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}